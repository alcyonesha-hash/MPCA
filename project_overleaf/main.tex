%%
%% CHI 2026 Poster Extended Abstract
%% 1-column format for anonymous submission
%%
\documentclass[manuscript, nonacm]{acmart}

%% Additional packages
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{multirow}

%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information (for draft/submission)
\setcopyright{none}
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Human-like Behavioral Dimensions in Multi-Party Chat Agents: \\
A User Perception Study}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
\author{Anonymous Author(s)}
\affiliation{%
  \institution{Anonymous Institution}
  \city{City}
  \country{Country}
}
\email{anonymous@example.com}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
As LLM-based agents become integrated into collaborative workspaces, their participation in multi-party chat environments raises new questions about social acceptability. Unlike traditional chatbots designed for dyadic interaction, agents in group settings must navigate complex social dynamics---knowing when to speak, how to pace responses, and how to avoid disrupting human conversation flow. These challenges are particularly salient for \textit{proxy agents} that represent users while they are multitasking or temporarily unavailable.

We identify three behavioral dimensions critical to perceived human-likeness: \textit{selectivity} (responding only to relevant messages), \textit{chunking} (breaking responses into multiple turns), and \textit{timing} (introducing natural delays). These dimensions were informed by interaction parameters derived from real IRC technical chat conversations.

Through a within-subjects study (N=XX) with A/B comparisons across 8 realistic scenarios, we evaluate how each dimension affects perceived human-likeness, intrusiveness, social acceptance, and user preference as a representative agent. Our findings contribute empirically grounded design guidelines for developing LLM agents that integrate more seamlessly into human group conversations.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003121.10003122</concept_id>
       <concept_desc>Human-centered computing~HCI design and evaluation methods</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
   <concept>
       <concept_id>10003120.10003121.10003125</concept_id>
       <concept_desc>Human-centered computing~User studies</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~HCI design and evaluation methods}
\ccsdesc[500]{Human-centered computing~User studies}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Conversational agents, Multi-party chat, Human-like behavior, Proxy agents, LLM}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

% ============================================
\section{Introduction}
% ============================================

AI-powered chat agents are increasingly expected to participate in group conversations rather than simply respond to isolated queries. However, most conversational AI systems are designed for one-on-one interactions, often exhibiting behaviors that feel mechanical or intrusive in multi-party settings~\cite{brandtzaeg2017people, gnewuch2017towards}.

Consider a workplace chat room where an AI assistant helps team members. A well-designed agent might wait for human responses first, contribute at appropriate moments, and avoid dominating the conversation. In contrast, a poorly designed agent might respond instantly to every message, overwhelming participants with walls of text and disrupting natural conversation flow.

This challenge is particularly relevant for \textbf{proxy agents}---AI systems that represent users in group chats while they are multitasking, in meetings, or temporarily unavailable. Such agents must balance being helpful with appearing natural and non-intrusive.

We investigate how specific behavioral characteristics affect user perception in multi-party environments, focusing on three dimensions derived from analysis of real IRC technical chat data:

\begin{enumerate}
    \item \textbf{Selectivity}: Responding only to contextually relevant messages rather than every utterance
    \item \textbf{Chunking}: Breaking responses into multiple shorter messages that mirror natural conversational pacing
    \item \textbf{Timing}: Introducing natural delays that simulate reading and thinking time
\end{enumerate}

Our research questions are:
\begin{itemize}
    \item \textbf{RQ1}: How does each behavioral dimension affect perceived human-likeness and naturalness?
    \item \textbf{RQ2}: Which dimensions most strongly influence user preference for an AI representative?
    \item \textbf{RQ3}: How do these dimensions affect perceived intrusiveness in group conversations?
\end{itemize}

% ============================================
\section{Related Work}
% ============================================

\textbf{Multi-Party Conversational AI.} While dyadic human-chatbot interactions have been extensively studied~\cite{brandtzaeg2017people}, multi-party conversational AI remains underexplored. Early work focused on meeting summarization and turn-taking prediction~\cite{traum2004multi}, with recent studies examining AI agent behavior with multiple humans present~\cite{bohus2010facilitating, matsuyama2015four}.

\textbf{Human-like Behavior in AI.} Making AI systems more human-like has roots in the ELIZA effect~\cite{weizenbaum1966eliza} and anthropomorphism research~\cite{nass1994computers, epley2007seeing}. Human-like characteristics can increase trust~\cite{waytz2014mind}, though overly human-like behavior may trigger uncanny valley effects~\cite{mori1970uncanny}.

\textbf{Response Timing and Chunking.} Response timing carries social meaning in human conversation~\cite{sacks1974simplest, levinson2015timing}. In chatbot design, typing indicators and response delays affect user perception~\cite{gnewuch2018faster}. Message chunking affects readability and perceived conversational naturalness~\cite{miller1956magical, kim2019comparing}.

% ============================================
\section{Method}
% ============================================

\subsection{Behavioral Dimensions from IRC Data}

We analyzed publicly available IRC technical support chat logs (Ubuntu channels) to identify behavioral parameters that distinguish human-like conversation patterns. This analysis informed our three experimental dimensions:

\begin{itemize}
    \item \textbf{Selectivity}: Human helpers typically respond to 40-60\% of messages in a thread, focusing on main topics while ignoring tangential comments
    \item \textbf{Chunking}: Responses averaging 2-4 separate messages rather than single comprehensive blocks
    \item \textbf{Timing}: Response delays of 3-8 seconds for reading, plus 2-4 seconds per response message
\end{itemize}

\subsection{Experimental Design}

We conducted a within-subjects study comparing agent behaviors across three pairs of conditions, each tested with two different conversation scenarios:

\begin{table}[h]
\caption{Experimental Conditions by Comparison Type}
\label{tab:conditions}
\small
\begin{tabular}{lp{2.8cm}p{2.8cm}}
\toprule
Dimension & Human-like & Non-human-like \\
\midrule
Selectivity & Responds to main thread topics only & Responds to every message including off-topic \\
Chunking & Multiple shorter messages (2-4 turns) & Single comprehensive message \\
Timing & Natural delays (3-8s reading + 2-4s/msg) & Instant responses \\
\bottomrule
\end{tabular}
\end{table}

Additionally, Sets 7-8 compared a ``full'' agent (all three human-like features + contextual responses) against a baseline agent providing generic, textbook-style responses.

\subsection{Conversation Scenarios}

We developed 8 realistic scenarios across diverse domains to ensure ecological validity:

\begin{table}[h]
\caption{Conversation Scenarios}
\label{tab:scenarios}
\small
\begin{tabular}{llll}
\toprule
Set & Topic & Domain & Dimension \\
\midrule
1 & Invoice/shipment tasks & Workplace & Selectivity \\
2 & GPT hallucination & AI/Tech & Selectivity \\
3 & Linux filesystem check & Tech support & Chunking \\
4 & Gnome suspend issue & Tech support & Chunking \\
5 & TensorFlow version & Programming & Timing \\
6 & Excel VLOOKUP error & Office work & Timing \\
7 & Book translation & Knowledge work & Combined \\
8 & Database selection & Programming & Combined \\
\bottomrule
\end{tabular}
\end{table}

Text-based comparisons (Sets 1-4) showed static conversation transcripts. Video-based comparisons (Sets 5-8) used animated visualizations to demonstrate timing differences, with messages appearing progressively to simulate real-time chat.

All conversations were presented bilingually (English with Korean translations) to accommodate our participant population.

\subsection{Measures}

For each A/B comparison, participants answered four forced-choice questions:

\begin{enumerate}
    \item \textbf{Human-likeness}: ``Which conversation feels more human-like?''
    \item \textbf{Intrusiveness}: ``Which conversation is less interruptive/annoying?''
    \item \textbf{Social Acceptance}: ``Which agent would other participants accept more naturally?''
    \item \textbf{Preference}: ``Which agent would you want as your representative?''
\end{enumerate}

A/B positioning was randomized per participant per set to control for order effects.

\subsection{Participants and Procedure}

Participants were recruited through convenience sampling. After informed consent, they completed: (1) demographics (gender, age, IT experience, AI chatbot experience), (2) task instructions explaining the proxy agent concept, (3) 8 comparison sets in fixed order with randomized A/B positioning, and (4) debrief. The study took approximately 10 minutes.

[Participant demographics to be reported after data collection]

% ============================================
\section{Preliminary Findings}
% ============================================

[To be completed after data collection. We will report:]

\begin{itemize}
    \item Preference rates for each dimension across four measures
    \item Statistical significance using binomial tests
    \item Effect sizes and confidence intervals
    \item Demographic differences (IT experience, AI chatbot familiarity)
\end{itemize}

\textit{Expected patterns based on pilot testing:}
\begin{itemize}
    \item \textbf{Timing}: Strong preference for delayed responses over instant
    \item \textbf{Selectivity}: Moderate preference for selective engagement
    \item \textbf{Chunking}: Mixed results; some users may prefer comprehensive responses
\end{itemize}

% ============================================
\section{Design Implications}
% ============================================

Based on our framework and preliminary observations, we propose three design guidelines for multi-party chat agents:

\textbf{Design for Selective Engagement.} Agents should evaluate message relevance before responding. In group settings, not every message requires agent input---particularly off-topic comments or social exchanges between humans. Implementing topic relevance scoring can help agents decide when silence is more appropriate than response.

\textbf{Mirror Human Pacing Through Chunking.} Rather than delivering comprehensive responses in single messages, agents should break information into conversational chunks. This mirrors how humans naturally share information incrementally and allows other participants to interject or redirect.

\textbf{Simulate Cognitive Processing Time.} Instant responses signal artificiality. Agents should introduce delays that simulate reading comprehension and response formulation. For proxy agents specifically, this also creates space for the represented user to return and respond themselves.

% ============================================
\section{Limitations and Future Work}
% ============================================

\textbf{Limitations.} Our scenarios focus on technical support and workplace contexts; social or creative domains may yield different preferences. The bilingual presentation may affect perceptions. Video-based timing comparisons may conflate timing effects with other factors.

\textbf{Future Work.} We plan to: (1) conduct longitudinal studies of proxy agent usage in real workplace settings, (2) investigate interaction effects between dimensions, (3) explore personalization of behavioral parameters based on user preferences, and (4) extend to other multi-party contexts (gaming, education, social).

% ============================================
\section{Conclusion}
% ============================================

We present a framework for evaluating human-like behavioral dimensions in multi-party chat agents, grounded in IRC conversation analysis. Our within-subjects study examines how selectivity, chunking, and timing affect user perception across multiple metrics. The findings contribute design guidelines for developing AI agents---particularly proxy agents---that participate more naturally in group conversations, with implications for workplace assistants and collaborative tools.

%%
%% The acknowledgments section is defined using the "acks" environment
\begin{acks}
[To be added after review]
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
