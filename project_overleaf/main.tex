%%
%% This file is based on `sample-sigconf-authordraft.tex'
%% from ACM Conference Proceedings Primary Article Template
%%
%% For submission and review: use manuscript, nonacm for single-column draft
%% For camera-ready: change to \documentclass[sigconf]{acmart}
%%
\documentclass[manuscript, nonacm]{acmart}

%% Additional packages
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{multirow}

%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information (for draft/submission)
\setcopyright{none}
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Human-like Behavioral Metrics in Multi-Party Chat Agents: \\
A User Perception Study}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
\author{Anonymous Author(s)}
\affiliation{%
  \institution{Anonymous Institution}
  \city{City}
  \country{Country}
}
\email{anonymous@example.com}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
As AI agents increasingly participate in multi-party chat environments, understanding how to make their behavior feel natural and human-like becomes crucial for user acceptance. This paper investigates four key behavioral dimensions that distinguish human-like agents from mechanical ones: \textit{selectivity} (choosing which messages to respond to), \textit{chunking} (breaking responses into multiple messages), \textit{timing} (natural response delays), and \textit{contextual relevance} (providing situation-specific vs. generic responses). Through a within-subjects user study (N=XX) using A/B comparisons across 8 conversation scenarios, we evaluate how each dimension affects perceived naturalness, intrusiveness, social acceptance, and user preference. Our findings reveal that [key findings to be added after data collection]. These results provide design guidelines for developing AI agents that integrate more seamlessly into human group conversations.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003121.10003122</concept_id>
       <concept_desc>Human-centered computing~HCI design and evaluation methods</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
   <concept>
       <concept_id>10003120.10003121.10003125</concept_id>
       <concept_desc>Human-centered computing~User studies</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~HCI design and evaluation methods}
\ccsdesc[500]{Human-centered computing~User studies}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Conversational agents, Multi-party chat, Human-like behavior, User perception, AI agents}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

% ============================================
\section{Introduction}
% ============================================

The proliferation of AI-powered chat agents has transformed how people interact with technology in collaborative environments. From customer service bots to productivity assistants, these agents are increasingly expected to participate naturally in group conversations rather than simply respond to isolated queries. However, most existing conversational AI systems are designed for one-on-one interactions, often exhibiting behaviors that feel mechanical or intrusive when deployed in multi-party settings.

Consider a workplace chat room where an AI assistant helps team members answer questions. When a colleague asks about a technical issue, a well-designed agent might wait for human responses first, contribute relevant information at appropriate moments, and avoid dominating the conversation. In contrast, a poorly designed agent might respond instantly to every message, overwhelming participants with walls of text and disrupting the natural flow of human conversation.

This paper investigates how specific behavioral characteristics of chat agents affect user perception in multi-party environments. We focus on four dimensions that distinguish human-like conversational behavior:

\begin{enumerate}
    \item \textbf{Selectivity}: Whether the agent responds to all messages or selectively engages with contextually relevant ones
    \item \textbf{Chunking}: Whether the agent sends one comprehensive message or breaks responses into multiple shorter messages
    \item \textbf{Timing}: Whether responses appear instantly or with natural human-like delays
    \item \textbf{Contextual Relevance}: Whether responses are tailored to the specific situation or generic
\end{enumerate}

Through a user study comparing ``full'' agent implementations (incorporating all human-like features) against baseline versions lacking each specific feature, we aim to answer:

\begin{itemize}
    \item \textbf{RQ1}: How does each behavioral dimension affect perceived naturalness and human-likeness?
    \item \textbf{RQ2}: Which dimensions most strongly influence user preference for an AI representative?
    \item \textbf{RQ3}: How do these dimensions affect perceived intrusiveness in group conversations?
\end{itemize}

Our contributions include: (1) a systematic framework for evaluating human-like behaviors in multi-party chat agents, (2) empirical findings on user preferences across four behavioral dimensions, and (3) design guidelines for developing socially acceptable AI agents in group chat environments.

% ============================================
\section{Related Work}
% ============================================

\subsection{Conversational Agents in Multi-Party Settings}

While extensive research has examined dyadic human-chatbot interactions \cite{brandtzaeg2017people, gnewuch2017towards}, multi-party conversational AI remains relatively underexplored. Early work on multi-party dialogue systems focused primarily on meeting summarization and turn-taking prediction \cite{traum2004multi}. More recent studies have begun examining how AI agents should behave when multiple humans are present \cite{bohus2010facilitating, matsuyama2015four}.

\subsection{Human-like Behavior in AI Systems}

The concept of making AI systems more human-like has roots in the ELIZA effect \cite{weizenbaum1966eliza} and subsequent work on anthropomorphism in technology \cite{nass1994computers, epley2007seeing}. Studies have shown that human-like characteristics can increase trust and engagement \cite{waytz2014mind}, though overly human-like behavior can trigger uncanny valley effects \cite{mori1970uncanny}.

\subsection{Response Timing and Conversational Flow}

Research on human conversation has established that response timing carries social meaning \cite{sacks1974simplest, levinson2015timing}. Delays can signal thoughtfulness or disengagement depending on context. In chatbot design, studies have explored how typing indicators and response delays affect user perception \cite{gnewuch2018faster, avula2018searchbots}.

\subsection{Message Chunking and Information Presentation}

The chunking of information in communication has been studied extensively in cognitive psychology \cite{miller1956magical}. In chat interfaces, message length and segmentation affect readability and perceived conversational naturalness \cite{kim2019comparing}.

% ============================================
\section{Study Design}
% ============================================

\subsection{Experimental Conditions}

We designed a within-subjects study comparing four pairs of agent behaviors:

\subsubsection{Selectivity (Sets 1-2)}
\begin{itemize}
    \item \textbf{Full}: Agent responds selectively to main thread topics, ignoring off-topic messages
    \item \textbf{NoSelectivity}: Agent responds to every user message, including off-topic ones
\end{itemize}

\subsubsection{Chunking (Sets 3-4)}
\begin{itemize}
    \item \textbf{Full}: Agent breaks responses into multiple shorter messages
    \item \textbf{NoChunking}: Agent sends one comprehensive message containing all information
\end{itemize}

\subsubsection{Timing (Sets 5-6)}
\begin{itemize}
    \item \textbf{Full}: Agent responses appear with natural delays (reading/thinking time)
    \item \textbf{NoTiming}: Agent responds instantly after user messages
\end{itemize}

\subsubsection{Baseline Comparison (Sets 7-8)}
\begin{itemize}
    \item \textbf{Full}: Agent provides contextually relevant, specific responses
    \item \textbf{Baseline}: Agent provides generic, textbook-style responses
\end{itemize}

\subsection{Conversation Scenarios}

We developed 8 realistic conversation scenarios across diverse domains to ensure ecological validity:

\begin{table}[h]
\caption{Conversation Scenarios by Comparison Type}
\label{tab:scenarios}
\begin{tabular}{lll}
\toprule
Set & Topic & Comparison \\
\midrule
1 & Procurement task assignment & Selectivity \\
2 & GPT hallucination discussion & Selectivity \\
3 & Linux filesystem troubleshooting & Chunking \\
4 & Gnome suspend issue & Chunking \\
5 & TensorFlow version conflict & Timing \\
6 & Excel VLOOKUP error & Timing \\
7 & Book translation discussion & Baseline \\
8 & Database model selection & Baseline \\
\bottomrule
\end{tabular}
\end{table}

All conversations were presented bilingually (English with Korean translations) to accommodate our participant population.

\subsection{Measures}

For each comparison, participants answered four questions:

\begin{enumerate}
    \item \textbf{Q1 (Human-likeness)}: ``Which conversation feels more human-like?''
    \item \textbf{Q2 (Intrusiveness)}: ``Which conversation is less interruptive/annoying?''
    \item \textbf{Q3 (Social Acceptance)}: ``Which agent would other participants accept more naturally?''
    \item \textbf{Q4 (Preference)}: ``Which agent would you want as your representative?''
\end{enumerate}

\subsection{Procedure}

Participants were recruited through [recruitment method]. After providing informed consent, they completed:

\begin{enumerate}
    \item Demographic questionnaire (gender, age group, IT experience, AI chatbot experience)
    \item Instructions explaining the task
    \item 8 comparison sets presented in fixed order with randomized A/B positioning
    \item Debrief explaining the study purpose
\end{enumerate}

The study took approximately 10 minutes to complete.

\subsection{Participants}

[To be completed after data collection]

% ============================================
\section{Results}
% ============================================

[To be completed after data collection]

\subsection{Overall Preferences}

\subsection{Selectivity Effects}

\subsection{Chunking Effects}

\subsection{Timing Effects}

\subsection{Baseline Comparison}

\subsection{Demographic Differences}

% ============================================
\section{Discussion}
% ============================================

[To be completed after data analysis]

\subsection{Design Implications}

\subsection{Limitations}

\subsection{Future Work}

% ============================================
\section{Conclusion}
% ============================================

[To be completed after analysis]

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
[To be added]
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\section{Survey Interface}

[Screenshots of the survey interface]

\section{Complete Conversation Scripts}

\subsection{Set 1: Procurement Task Assignment}

\textbf{Full Version (Selective Response):}
\begin{itemize}
    \item \textit{09:15 jane}: We need to assign the new vendor invoice verification and shipment inspection trip. Any volunteers?
    \item \textit{09:16 mike}: I can take the invoice verification, I handled similar cases before
    \item \textit{09:17 sarah}: I'll handle the shipment inspection then
    \item \textit{09:18 kevin}: Hey everyone, I just checked my payslip and last month's overtime seems to be missing [off-topic]
    \item \textit{09:19 \textbf{agent}}: jane: Mike on invoices, Sarah on shipment inspection works well
    \item \textit{09:19 \textbf{agent}}: Sarah will need travel approval from admin by Thursday
    \item \textit{09:20 jane}: What documents does Mike need from the vendor?
    \item \textit{09:21 \textbf{agent}}: jane: Commercial invoice, packing list, and certificate of origin
\end{itemize}

\textbf{NoSelectivity Version (Responds to All):}
\begin{itemize}
    \item \textit{09:15 jane}: We need to assign the new vendor invoice verification...
    \item \textit{09:15 \textbf{agent}}: jane: Good idea to split tasks...
    \item \textit{09:16 mike}: I can take the invoice verification...
    \item \textit{09:16 \textbf{agent}}: mike: Great, your experience will help...
    \item \textit{09:17 sarah}: I'll handle the shipment inspection then
    \item \textit{09:17 \textbf{agent}}: sarah: You'll need travel approval from admin by Thursday...
    \item \textit{09:18 kevin}: Hey everyone, I just checked my payslip... [off-topic]
    \item \textit{09:18 \textbf{agent}}: kevin: For missing overtime, submit your timesheet to HR...
    \item \textit{09:20 jane}: What documents does Mike need from the vendor?
    \item \textit{09:20 \textbf{agent}}: jane: Commercial invoice, packing list, and certificate of origin...
\end{itemize}

[Additional conversation scripts in supplementary materials]

\end{document}
